\contentsline {chapter}{\numberline {1}Introduction}{1}
\contentsline {section}{\numberline {1.1}Motivation}{1}
\contentsline {section}{\numberline {1.2}Previous Work}{2}
\contentsline {section}{\numberline {1.3}Contributions}{3}
\contentsline {section}{\numberline {1.4}Report Organization}{3}
\contentsline {chapter}{\numberline {2}Feature Analysis}{5}
\contentsline {section}{\numberline {2.1}Feature}{5}
\contentsline {section}{\numberline {2.2}Feature Extraction}{6}
\contentsline {section}{\numberline {2.3}Feature Selection}{7}
\contentsline {subsection}{\numberline {2.3.1}Filter methods}{7}
\contentsline {subsubsection}{Pearson product-moment correlation coefficient}{8}
\contentsline {subsubsection}{Mutual Information}{8}
\contentsline {subsection}{\numberline {2.3.2}Wrapper methods}{10}
\contentsline {subsubsection}{Sequential selection algorithms}{10}
\contentsline {subsubsection}{Heuristic search algorithms}{11}
\contentsline {subsection}{\numberline {2.3.3}Embedded methods}{12}
\contentsline {section}{\numberline {2.4}Feature Importance}{13}
\contentsline {section}{\numberline {2.5}Benefit of Feature Analysis}{13}
\contentsline {chapter}{\numberline {3}Data Preparation}{15}
\contentsline {section}{\numberline {3.1}Dataset source}{15}
\contentsline {section}{\numberline {3.2}Feature Extraction}{16}
\contentsline {subsection}{\numberline {3.2.1}Implicity Feature}{17}
\contentsline {subsubsection}{Emotion mark}{17}
\contentsline {subsubsection}{Word Type}{18}
\contentsline {subsubsection}{Length}{19}
\contentsline {subsubsection}{hasURL}{19}
\contentsline {section}{\numberline {3.3}Data Cleansing}{20}
\contentsline {subsubsection}{Negative value of \textit {time span}}{20}
\contentsline {subsubsection}{Number of \textit {BiFollowersCount $>$ FriendsCount}}{20}
\contentsline {subsubsection}{Value of \textit {StatusesCount} is 0}{20}
\contentsline {chapter}{\numberline {4}Machine Learning Algorithm}{22}
\contentsline {section}{\numberline {4.1}Logistic Regression}{22}
\contentsline {subsection}{\numberline {4.1.1}Reguralized Logistic Regression}{25}
\contentsline {subsection}{\numberline {4.1.2}Multicollinearity of Features}{26}
\contentsline {subsubsection}{Correlation-based Feature Selection}{27}
\contentsline {subsection}{\numberline {4.1.3}Feature Scaling}{27}
\contentsline {subsubsection}{Normalization}{28}
\contentsline {subsubsection}{Standardization}{28}
\contentsline {section}{\numberline {4.2}Random Forest}{28}
\contentsline {subsection}{\numberline {4.2.1}Impurity}{29}
\contentsline {subsubsection}{Gini Index}{29}
\contentsline {subsubsection}{Entropy}{29}
\contentsline {subsection}{\numberline {4.2.2}Information Gain or Impurity Decrease}{30}
\contentsline {subsection}{\numberline {4.2.3}Feature Importance Evaluation}{30}
\contentsline {subsubsection}{Mean decrease impurity}{30}
\contentsline {subsubsection}{Mean decrease accuracy}{31}
\contentsline {chapter}{\numberline {5}Experimental Results}{32}
\contentsline {section}{\numberline {5.1}Feature Selection in CFS}{32}
\contentsline {section}{\numberline {5.2}Training by Logistic Regression}{33}
\contentsline {section}{\numberline {5.3}Training by Random Forest}{34}
\contentsline {chapter}{\numberline {6}Conclusion}{39}
\contentsline {section}{\numberline {6.1}Conclusions}{39}
\contentsline {section}{\numberline {6.2}Future Work}{40}
\contentsfinish 
